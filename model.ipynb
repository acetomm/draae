{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from twinmnist import TwinMnist\n",
    "from conf import X_DIM, C_DIM, S_DIM, MODEL_FILE\n",
    "from conf import e, es, ec, ec_tail, d\n",
    "from conf import sdc, cdc\n",
    "from conf import rs, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.placeholder(tf.float32, [None, X_DIM], name='x1')\n",
    "x2 = tf.placeholder(tf.float32, [None, X_DIM], name='x2')\n",
    "xc = tf.placeholder(tf.float32, [None, X_DIM], name='xc')\n",
    "s = tf.placeholder(tf.float32, [None, S_DIM], name='s')\n",
    "c = tf.placeholder(tf.float32, [None, C_DIM], name='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_z, x2_z, xc_z = e(x1), e(x2), e(xc)\n",
    "x1_ct, x2_ct, xc_ct = ec(x1_z), ec(x2_z), ec(xc_z)\n",
    "x1_c, x2_c, xc_c = ec_tail(x1_ct), ec_tail(x2_ct), ec_tail(xc_ct)\n",
    "x1_s = es(x1_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_r = d(tf.concat([x1_c, x1_s], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_real = sdc(s)\n",
    "sdc_fake = sdc(x1_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_real = cdc(c)\n",
    "cdc_fake = cdc(x1_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_loss = tf.reduce_mean(tf.square(x1 - x1_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .2\n",
    "loss_term = tf.reduce_sum(tf.square(x1_ct - x2_ct), 1) - tf.reduce_sum(tf.square(x1_ct - xc_ct), 1) + h\n",
    "triplet_loss = tf.reduce_mean(tf.maximum(0., loss_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdc_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(sdc_real), logits=sdc_real))\n",
    "sdc_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(sdc_fake), logits=sdc_fake))\n",
    "sdc_loss = sdc_real_loss + sdc_fake_loss\n",
    "\n",
    "sdc_e_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(sdc_fake), logits=sdc_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdc_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(cdc_real), logits=cdc_real))\n",
    "cdc_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.zeros_like(cdc_fake), logits=cdc_fake))\n",
    "cdc_loss = cdc_real_loss + cdc_fake_loss\n",
    "\n",
    "cdc_e_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf.ones_like(cdc_fake), logits=cdc_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = tf.trainable_variables()\n",
    "e_vars = [v for v in all_variables if v.name.startswith('es_')]\n",
    "ec_vars = [v for v in all_variables if v.name.startswith('e_c_')]\n",
    "ae_vars = [v for v in all_variables if v.name.startswith('e_') or v.name.startswith('d_') or v.name.startswith('es_')]\n",
    "#ec_vars = [v for v in all_variables if v.name.startswith('ec_')]\n",
    "sdc_vars = [v for v in all_variables if v.name.startswith('sdc_')]\n",
    "cdc_vars = [v for v in all_variables if v.name.startswith('cdc_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# things to think:\n",
    "# - use different learning rate (different optimizers)\n",
    "# - greater learning rate for triplet (or pretrain on batches)\n",
    "# - make style part of the encoder shorter (to prevent ignoring content)\n",
    "\n",
    "learning_rate = 0.001 # AdamOptimizer default 0.001\n",
    "ae_opt = tf.train.AdamOptimizer(learning_rate).minimize(ae_loss, var_list=ae_vars)\n",
    "\n",
    "triplet_opt = tf.train.AdamOptimizer(learning_rate).minimize(triplet_loss) # , var_list=ec_vars\n",
    "\n",
    "sdc_opt = tf.train.AdamOptimizer(learning_rate).minimize(sdc_loss, var_list=sdc_vars)\n",
    "sdc_e_opt = tf.train.AdamOptimizer(learning_rate).minimize(sdc_e_loss, var_list=e_vars)\n",
    "\n",
    "cdc_opt = tf.train.AdamOptimizer(learning_rate).minimize(cdc_loss, var_list=cdc_vars)\n",
    "cdc_e_opt = tf.train.AdamOptimizer(learning_rate).minimize(cdc_e_loss, var_list=ec_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('ae_loss', ae_loss)\n",
    "tf.summary.scalar('triplet_loss', triplet_loss)\n",
    "tf.summary.scalar('sdc_loss', sdc_loss)\n",
    "tf.summary.scalar('sdc_e_loss', sdc_e_loss)\n",
    "tf.summary.scalar('cdc_loss', cdc_loss)\n",
    "tf.summary.scalar('cdc_e_loss', cdc_e_loss)\n",
    "\n",
    "tf.summary.histogram('x1_c', x1_c)\n",
    "tf.summary.histogram('x1_s', x1_s)\n",
    "#tf.summary.histogram('s', s)\n",
    "\n",
    "#tf.summary.image('x1', tf.reshape(x1, [-1, 28, 28, 1]), 1)\n",
    "\n",
    "#tf.summary.image('x1_r', tf.reshape(x1_r, [-1, 28, 28, 1]), 1)\n",
    "\n",
    "#tf.summary.image('x_c1s2_r', tf.reshape(d(tf.concat([x1_c, x2_s], axis=1)), [-1, 28, 28, 1]), 1)\n",
    "#tf.summary.image('x_c2s1_r', tf.reshape(d(tf.concat([x2_c, x1_s], axis=1)), [-1, 28, 28, 1]), 1)\n",
    "\n",
    "all_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('summary', sess.graph)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tm = TwinMnist(train_dir='MNIST_data', validation_size=0)\n",
    "tm.load_triplets('mnist_triplets_k100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 100\n",
    "batches = tm.mnist.train.images.shape[0] // batch_size\n",
    "batch_end = epochs*batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35  88 %"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0447c44ec4aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdc_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx1_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ms_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdc_e_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx1_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcdc_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx1_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(1, epochs + 1):\n",
    "    for b in range(1, batches + 1):\n",
    "        x1_batch, x2_batch, xc_batch = tm.next_batch_triplets(batch_size)\n",
    "        s_batch = rs(batch_size)\n",
    "        c_batch = rc(batch_size)\n",
    "        \n",
    "        #sess.run(triplet_opt, {x1: x1_batch, x2: x2_batch, xc: xc_batch})\n",
    "        \n",
    "        sess.run([ae_opt, triplet_opt], {x1: x1_batch, x2: x2_batch, xc: xc_batch})\n",
    "        \n",
    "        sess.run(sdc_opt, {x1: x1_batch, s: s_batch})\n",
    "        sess.run(sdc_e_opt, {x1: x1_batch})\n",
    "        \n",
    "        sess.run(cdc_opt, {x1: x1_batch, c: c_batch})\n",
    "        sess.run(cdc_e_opt, {x1: x1_batch})\n",
    "        \n",
    "        batch_step += 1\n",
    "        print('\\repoch {0} {1:3.0f} %'.format(e, b / batches * 100), end='', flush=True)\n",
    "        summary_str = sess.run(all_summary, {\n",
    "            x1: x1_batch,\n",
    "            x2: x2_batch,\n",
    "            xc: xc_batch,\n",
    "            s: s_batch,\n",
    "            c: c_batch\n",
    "        })\n",
    "        writer.add_summary(summary_str, batch_step)\n",
    "print('\\rDone', ' '*25, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, MODEL_FILE)\n",
    "writer.close()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
